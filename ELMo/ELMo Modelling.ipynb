{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "established-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from scipy import spatial\n",
    "import torch\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "straight-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training dataset\n",
    "#train = open('data/train/train_QA.xlsx',)\n",
    "train_QA = pd.read_excel(r'data/train/train_QA.xlsx')\n",
    "train_context = pd.read_excel(r'data/train/train_context.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "changing-repair",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>contextID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina consists of three main geograph...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The coastal plain transitions to the Piedmont ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The western section of the state is part of th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The climate of the coastal plain is influenced...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Atlantic Ocean has less influence on the c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  contextID\n",
       "0  North Carolina consists of three main geograph...          1\n",
       "1  The coastal plain transitions to the Piedmont ...          2\n",
       "2  The western section of the state is part of th...          3\n",
       "3  The climate of the coastal plain is influenced...          4\n",
       "4  The Atlantic Ocean has less influence on the c...          5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_context.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subject-support",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 00:54:44,756 : INFO : Loading model from elmopath...\n",
      "2021-02-17 00:54:44,760 : INFO : No vocabulary file found in the model.\n",
      "2021-02-17 00:54:44,762 : INFO : No vocabulary file provided; using special tokens only.\n",
      "2021-02-17 00:54:44,763 : INFO : We will cache the vocabulary of 3 tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\envs\\Capstone\\lib\\site-packages\\simple_elmo\\model.py:570: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "2021-02-17 00:54:45,887 : WARNING : From C:\\Users\\User\\anaconda3\\envs\\Capstone\\lib\\site-packages\\simple_elmo\\model.py:570: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:981: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 00:54:46,732 : WARNING : From C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:981: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The model is now loaded.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simple_elmo import ElmoModel\n",
    "model = ElmoModel()\n",
    "model.load(r'elmopath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distributed-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I love potatoes', 'Tzemeng loves mala', 'Hazel loves Xiao', 'xingying loves anime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charming-voice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 00:54:59,541 : INFO : Warming up ELMo on 4 sentences...\n",
      "2021-02-17 00:55:00,459 : INFO : Warming up finished.\n",
      "2021-02-17 00:55:00,462 : INFO : Texts in the current batch: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.19745192, -0.41884196, -0.07295133, ..., -0.2019807 ,\n",
       "         -0.11709898,  0.21184988],\n",
       "        [-0.02613379, -0.33026373,  0.31403264, ..., -0.02769373,\n",
       "         -0.03423417,  0.05347976],\n",
       "        [ 0.05580795, -0.45201886,  0.46087283, ...,  0.16257262,\n",
       "         -0.30399969,  0.17682366],\n",
       "        ...,\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637],\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637],\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637]],\n",
       "\n",
       "       [[-0.62830472, -0.31021583,  0.48361775, ...,  0.07993049,\n",
       "         -0.27295381,  0.27352491],\n",
       "        [-0.5490095 , -0.28553104,  0.6998781 , ...,  0.01919892,\n",
       "         -0.36845356,  0.1718657 ],\n",
       "        [-0.3555795 ,  0.06677981,  0.37380549, ..., -0.06110012,\n",
       "         -0.45065731,  0.18366686],\n",
       "        ...,\n",
       "        [-0.11399087, -0.69189274,  0.29673722, ..., -0.21818581,\n",
       "         -0.31769109,  0.10352661],\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637],\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637]],\n",
       "\n",
       "       [[-0.36804533, -0.25667924,  0.0156424 , ..., -0.10074968,\n",
       "         -0.37100786,  0.36546057],\n",
       "        [-0.20788147, -1.02089369,  0.58674145, ..., -0.15905765,\n",
       "         -0.63146102,  0.23863101],\n",
       "        [-0.18462673, -0.0643319 ,  0.48617443, ..., -0.10709909,\n",
       "         -0.42204535,  0.17395781],\n",
       "        ...,\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637],\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637],\n",
       "        [ 0.00173837, -0.01513954,  0.05382365, ...,  0.04019766,\n",
       "         -0.07493153,  0.00220637]],\n",
       "\n",
       "       [[-0.44570097, -0.37916979,  0.52824551, ...,  0.20440412,\n",
       "         -0.42534527,  0.23011769],\n",
       "        [-0.51886225, -0.2717886 ,  0.71673352, ...,  0.03298841,\n",
       "         -0.39310831,  0.33695346],\n",
       "        [-0.15772025,  0.28256828,  0.28172871, ...,  0.51234496,\n",
       "         -0.39021033,  0.35099506],\n",
       "        ...,\n",
       "        [-0.26662689, -0.32508624,  0.5203504 , ..., -0.16040064,\n",
       "         -0.11649157,  0.19642417],\n",
       "        [-0.16506952, -0.0139496 ,  0.08872951, ..., -0.42552707,\n",
       "         -0.1492946 , -0.09809762],\n",
       "        [-0.15972859,  0.06283095,  0.42403573, ..., -0.40038377,\n",
       "         -0.22677623,  0.04326809]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The get_elmo_vectors() method produces a tensor of contextualized word embeddings. \n",
    "# Its shape is (number of sentences, the length of the longest sentence, ELMo dimensionality).\n",
    "model.get_elmo_vectors(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medieval-charge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 00:55:09,573 : INFO : Warming up ELMo on 4 sentences...\n",
      "2021-02-17 00:55:10,421 : INFO : Warming up finished.\n",
      "2021-02-17 00:55:10,423 : INFO : Texts in the current batch: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01197572, -0.03256201,  0.05645592, ..., -0.00174162,\n",
       "        -0.03306543,  0.02126458],\n",
       "       [-0.0231729 , -0.02101358,  0.04614951, ...,  0.0109503 ,\n",
       "        -0.05248468,  0.01727588],\n",
       "       [-0.02600693, -0.03952937,  0.06087819, ..., -0.00616964,\n",
       "        -0.06249807,  0.02318627],\n",
       "       [-0.0298245 , -0.01185991,  0.04964055, ...,  0.01127442,\n",
       "        -0.04647353,  0.02058413]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_elmo_vector_average(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-nepal",
   "metadata": {},
   "source": [
    "Experimenting with yuanxiaosc ElMo model\n",
    "https://github.com/yuanxiaosc/ELMo/blob/master/allennlp_elmo_use_examples/IMDB_ELMo_Preprocessing_Data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "northern-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "\u001b[2K[+] Loaded compatibility table\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.0.3) =================\u001b[0m\n",
      "[i] spaCy installation:\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\n",
      "\n",
      "NAME             SPACY            VERSION      \n",
      "en_core_web_sm   >=3.0.0,<3.1.0   3.0.0     [+]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 01:24:11.766787: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-02-17 01:24:11.766827: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "republican-library",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E049] Can't find spaCy data directory: 'None'. Check your installation and permissions, or use spacy.util.set_data_path to customise the location if necessary.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-316b29f40654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'parser'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tagger'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'textcat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m def load(\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mdisable\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimpleFrozenList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimpleFrozenList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE095\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \"\"\"Initialize the frozen dict. Can be initialized with pre-defined\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E049] Can't find spaCy data directory: 'None'. Check your installation and permissions, or use spacy.util.set_data_path to customise the location if necessary."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "removed-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 100000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 100\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coordinated-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_spacy_segmented_words(a_text_sentence):\n",
    "    doc = nlp(a_text_sentence)\n",
    "    token_list = [token for token in doc]\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continuous-abortion",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_SEQUENCE_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-eacf3538ab73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mpadding_cut_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafram_cut_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mraw_cut_text_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafram_cut_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mraw_cut_text_len\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdatafram_cut_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MAX_SEQUENCE_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "def padding_cut_text(datafram_cut_text, MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH):\n",
    "    raw_cut_text_len = len(datafram_cut_text)\n",
    "    if raw_cut_text_len >= MAX_SEQUENCE_LENGTH:\n",
    "        return datafram_cut_text[:MAX_SEQUENCE_LENGTH]\n",
    "    else:\n",
    "        datafram_cut_text += [\"\" for _ in range(MAX_SEQUENCE_LENGTH - raw_cut_text_len)] \n",
    "        return datafram_cut_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-roman",
   "metadata": {},
   "source": [
    "Experimenting with BILM from ALLENNLP repo\n",
    "https://github.com/allenai/bilm-tf/tree/master/bilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "emerging-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/allenai/bilm-tf/blob/master/bilm/model.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import json\n",
    "import re\n",
    "\n",
    "from ipynb.fs.full.elmodata import UnicodeCharsVocabulary, Batcher\n",
    "\n",
    "DTYPE = 'float32'\n",
    "DTYPE_INT = 'int64'\n",
    "\n",
    "\n",
    "class BidirectionalLanguageModel(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            options_file: str,\n",
    "            weight_file: str,\n",
    "            use_character_inputs=True,\n",
    "            embedding_weight_file=None,\n",
    "            max_batch_size=128,\n",
    "        ):\n",
    "        '''\n",
    "        Creates the language model computational graph and loads weights\n",
    "        Two options for input type:\n",
    "            (1) To use character inputs (paired with Batcher)\n",
    "                pass use_character_inputs=True, and ids_placeholder\n",
    "                of shape (None, None, max_characters_per_token)\n",
    "                to __call__\n",
    "            (2) To use token ids as input (paired with TokenBatcher),\n",
    "                pass use_character_inputs=False and ids_placeholder\n",
    "                of shape (None, None) to __call__.\n",
    "                In this case, embedding_weight_file is also required input\n",
    "        options_file: location of the json formatted file with\n",
    "                      LM hyperparameters\n",
    "        weight_file: location of the hdf5 file with LM weights\n",
    "        use_character_inputs: if True, then use character ids as input,\n",
    "            otherwise use token ids\n",
    "        max_batch_size: the maximum allowable batch size \n",
    "        '''\n",
    "        with open(options_file, 'r') as fin:\n",
    "            options = json.load(fin)\n",
    "\n",
    "        if not use_character_inputs:\n",
    "            if embedding_weight_file is None:\n",
    "                raise ValueError(\n",
    "                    \"embedding_weight_file is required input with \"\n",
    "                    \"not use_character_inputs\"\n",
    "                )\n",
    "\n",
    "        self._options = options\n",
    "        self._weight_file = weight_file\n",
    "        self._embedding_weight_file = embedding_weight_file\n",
    "        self._use_character_inputs = use_character_inputs\n",
    "        self._max_batch_size = max_batch_size\n",
    "\n",
    "        self._ops = {}\n",
    "        self._graphs = {}\n",
    "\n",
    "    def __call__(self, ids_placeholder):\n",
    "        '''\n",
    "        Given the input character ids (or token ids), returns a dictionary\n",
    "            with tensorflow ops:\n",
    "            {'lm_embeddings': embedding_op,\n",
    "             'lengths': sequence_lengths_op,\n",
    "             'mask': op to compute mask}\n",
    "        embedding_op computes the LM embeddings and is shape\n",
    "            (None, 3, None, 1024)\n",
    "        lengths_op computes the sequence lengths and is shape (None, )\n",
    "        mask computes the sequence mask and is shape (None, None)\n",
    "        ids_placeholder: a tf.placeholder of type int32.\n",
    "            If use_character_inputs=True, it is shape\n",
    "                (None, None, max_characters_per_token) and holds the input\n",
    "                character ids for a batch\n",
    "            If use_character_input=False, it is shape (None, None) and\n",
    "                holds the input token ids for a batch\n",
    "        '''\n",
    "        if ids_placeholder in self._ops:\n",
    "            # have already created ops for this placeholder, just return them\n",
    "            ret = self._ops[ids_placeholder]\n",
    "\n",
    "        else:\n",
    "            # need to create the graph\n",
    "            if len(self._ops) == 0:\n",
    "                # first time creating the graph, don't reuse variables\n",
    "                lm_graph = BidirectionalLanguageModelGraph(\n",
    "                    self._options,\n",
    "                    self._weight_file,\n",
    "                    ids_placeholder,\n",
    "                    embedding_weight_file=self._embedding_weight_file,\n",
    "                    use_character_inputs=self._use_character_inputs,\n",
    "                    max_batch_size=self._max_batch_size)\n",
    "            else:\n",
    "                with tf.variable_scope('', reuse=True):\n",
    "                    lm_graph = BidirectionalLanguageModelGraph(\n",
    "                        self._options,\n",
    "                        self._weight_file,\n",
    "                        ids_placeholder,\n",
    "                        embedding_weight_file=self._embedding_weight_file,\n",
    "                        use_character_inputs=self._use_character_inputs,\n",
    "                        max_batch_size=self._max_batch_size)\n",
    "\n",
    "            ops = self._build_ops(lm_graph)\n",
    "            self._ops[ids_placeholder] = ops\n",
    "            self._graphs[ids_placeholder] = lm_graph\n",
    "            ret = ops\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _build_ops(self, lm_graph):\n",
    "        with tf.control_dependencies([lm_graph.update_state_op]):\n",
    "            # get the LM embeddings\n",
    "            token_embeddings = lm_graph.embedding\n",
    "            layers = [\n",
    "                tf.concat([token_embeddings, token_embeddings], axis=2)\n",
    "            ]\n",
    "\n",
    "            n_lm_layers = len(lm_graph.lstm_outputs['forward'])\n",
    "            for i in range(n_lm_layers):\n",
    "                layers.append(\n",
    "                    tf.concat(\n",
    "                        [lm_graph.lstm_outputs['forward'][i],\n",
    "                         lm_graph.lstm_outputs['backward'][i]],\n",
    "                        axis=-1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # The layers include the BOS/EOS tokens.  Remove them\n",
    "            sequence_length_wo_bos_eos = lm_graph.sequence_lengths - 2\n",
    "            layers_without_bos_eos = []\n",
    "            for layer in layers:\n",
    "                layer_wo_bos_eos = layer[:, 1:, :]\n",
    "                layer_wo_bos_eos = tf.reverse_sequence(\n",
    "                    layer_wo_bos_eos, \n",
    "                    lm_graph.sequence_lengths - 1,\n",
    "                    seq_axis=1,\n",
    "                    batch_axis=0,\n",
    "                )\n",
    "                layer_wo_bos_eos = layer_wo_bos_eos[:, 1:, :]\n",
    "                layer_wo_bos_eos = tf.reverse_sequence(\n",
    "                    layer_wo_bos_eos,\n",
    "                    sequence_length_wo_bos_eos,\n",
    "                    seq_axis=1,\n",
    "                    batch_axis=0,\n",
    "                )\n",
    "                layers_without_bos_eos.append(layer_wo_bos_eos)\n",
    "\n",
    "            # concatenate the layers\n",
    "            lm_embeddings = tf.concat(\n",
    "                [tf.expand_dims(t, axis=1) for t in layers_without_bos_eos],\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            # get the mask op without bos/eos.\n",
    "            # tf doesn't support reversing boolean tensors, so cast\n",
    "            # to int then back\n",
    "            mask_wo_bos_eos = tf.cast(lm_graph.mask[:, 1:], 'int32')\n",
    "            mask_wo_bos_eos = tf.reverse_sequence(\n",
    "                mask_wo_bos_eos,\n",
    "                lm_graph.sequence_lengths - 1,\n",
    "                seq_axis=1,\n",
    "                batch_axis=0,\n",
    "            )\n",
    "            mask_wo_bos_eos = mask_wo_bos_eos[:, 1:]\n",
    "            mask_wo_bos_eos = tf.reverse_sequence(\n",
    "                mask_wo_bos_eos,\n",
    "                sequence_length_wo_bos_eos,\n",
    "                seq_axis=1,\n",
    "                batch_axis=0,\n",
    "            )\n",
    "            mask_wo_bos_eos = tf.cast(mask_wo_bos_eos, 'bool')\n",
    "\n",
    "        return {\n",
    "            'lm_embeddings': lm_embeddings, \n",
    "            'lengths': sequence_length_wo_bos_eos,\n",
    "            'token_embeddings': lm_graph.embedding,\n",
    "            'mask': mask_wo_bos_eos,\n",
    "        }\n",
    "\n",
    "\n",
    "def _pretrained_initializer(varname, weight_file, embedding_weight_file=None):\n",
    "    '''\n",
    "    We'll stub out all the initializers in the pretrained LM with\n",
    "    a function that loads the weights from the file\n",
    "    '''\n",
    "    weight_name_map = {}\n",
    "    for i in range(2):\n",
    "        for j in range(8):  # if we decide to add more layers\n",
    "            root = 'RNN_{}/RNN/MultiRNNCell/Cell{}'.format(i, j)\n",
    "            weight_name_map[root + '/rnn/lstm_cell/kernel'] = \\\n",
    "                root + '/LSTMCell/W_0'\n",
    "            weight_name_map[root + '/rnn/lstm_cell/bias'] = \\\n",
    "                root + '/LSTMCell/B'\n",
    "            weight_name_map[root + '/rnn/lstm_cell/projection/kernel'] = \\\n",
    "                root + '/LSTMCell/W_P_0'\n",
    "\n",
    "    # convert the graph name to that in the checkpoint\n",
    "    varname_in_file = varname[5:]\n",
    "    if varname_in_file.startswith('RNN'):\n",
    "        varname_in_file = weight_name_map[varname_in_file]\n",
    "\n",
    "    if varname_in_file == 'embedding':\n",
    "        with h5py.File(embedding_weight_file, 'r') as fin:\n",
    "            # Have added a special 0 index for padding not present\n",
    "            # in the original model.\n",
    "            embed_weights = fin[varname_in_file][...]\n",
    "            weights = np.zeros(\n",
    "                (embed_weights.shape[0] + 1, embed_weights.shape[1]),\n",
    "                dtype=DTYPE\n",
    "            )\n",
    "            weights[1:, :] = embed_weights\n",
    "    else:\n",
    "        with h5py.File(weight_file, 'r') as fin:\n",
    "            if varname_in_file == 'char_embed':\n",
    "                # Have added a special 0 index for padding not present\n",
    "                # in the original model.\n",
    "                char_embed_weights = fin[varname_in_file][...]\n",
    "                weights = np.zeros(\n",
    "                    (char_embed_weights.shape[0] + 1,\n",
    "                     char_embed_weights.shape[1]),\n",
    "                    dtype=DTYPE\n",
    "                )\n",
    "                weights[1:, :] = char_embed_weights\n",
    "            else:\n",
    "                weights = fin[varname_in_file][...]\n",
    "\n",
    "    # Tensorflow initializers are callables that accept a shape parameter\n",
    "    # and some optional kwargs\n",
    "    def ret(shape, **kwargs):\n",
    "        if list(shape) != list(weights.shape):\n",
    "            raise ValueError(\n",
    "                \"Invalid shape initializing {0}, got {1}, expected {2}\".format(\n",
    "                    varname_in_file, shape, weights.shape)\n",
    "            )\n",
    "        return weights\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "class BidirectionalLanguageModelGraph(object):\n",
    "    '''\n",
    "    Creates the computational graph and holds the ops necessary for runnint\n",
    "    a bidirectional language model\n",
    "    '''\n",
    "    def __init__(self, options, weight_file, ids_placeholder,\n",
    "                 use_character_inputs=True, embedding_weight_file=None,\n",
    "                 max_batch_size=128):\n",
    "\n",
    "        self.options = options\n",
    "        self._max_batch_size = max_batch_size\n",
    "        self.ids_placeholder = ids_placeholder\n",
    "        self.use_character_inputs = use_character_inputs\n",
    "\n",
    "        # this custom_getter will make all variables not trainable and\n",
    "        # override the default initializer\n",
    "        def custom_getter(getter, name, *args, **kwargs):\n",
    "            kwargs['trainable'] = False\n",
    "            kwargs['initializer'] = _pretrained_initializer(\n",
    "                name, weight_file, embedding_weight_file\n",
    "            )\n",
    "            return getter(name, *args, **kwargs)\n",
    "\n",
    "        if embedding_weight_file is not None:\n",
    "            # get the vocab size\n",
    "            with h5py.File(embedding_weight_file, 'r') as fin:\n",
    "                # +1 for padding\n",
    "                self._n_tokens_vocab = fin['embedding'].shape[0] + 1\n",
    "        else:\n",
    "            self._n_tokens_vocab = None\n",
    "\n",
    "        with tf.variable_scope('bilm', custom_getter=custom_getter):\n",
    "            self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        if self.use_character_inputs:\n",
    "            self._build_word_char_embeddings()\n",
    "        else:\n",
    "            self._build_word_embeddings()\n",
    "        self._build_lstms()\n",
    "\n",
    "    def _build_word_char_embeddings(self):\n",
    "        '''\n",
    "        options contains key 'char_cnn': {\n",
    "        'n_characters': 262,\n",
    "        # includes the start / end characters\n",
    "        'max_characters_per_token': 50,\n",
    "        'filters': [\n",
    "            [1, 32],\n",
    "            [2, 32],\n",
    "            [3, 64],\n",
    "            [4, 128],\n",
    "            [5, 256],\n",
    "            [6, 512],\n",
    "            [7, 512]\n",
    "        ],\n",
    "        'activation': 'tanh',\n",
    "        # for the character embedding\n",
    "        'embedding': {'dim': 16}\n",
    "        # for highway layers\n",
    "        # if omitted, then no highway layers\n",
    "        'n_highway': 2,\n",
    "        }\n",
    "        '''\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "\n",
    "        cnn_options = self.options['char_cnn']\n",
    "        filters = cnn_options['filters']\n",
    "        n_filters = sum(f[1] for f in filters)\n",
    "        max_chars = cnn_options['max_characters_per_token']\n",
    "        char_embed_dim = cnn_options['embedding']['dim']\n",
    "        n_chars = cnn_options['n_characters']\n",
    "        if n_chars != 262:\n",
    "            raise InvalidNumberOfCharacters(\n",
    "                \"Set n_characters=262 after training see the README.md\"\n",
    "            )\n",
    "        if cnn_options['activation'] == 'tanh':\n",
    "            activation = tf.nn.tanh\n",
    "        elif cnn_options['activation'] == 'relu':\n",
    "            activation = tf.nn.relu\n",
    "\n",
    "        # the character embeddings\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.embedding_weights = tf.get_variable(\n",
    "                    \"char_embed\", [n_chars, char_embed_dim],\n",
    "                    dtype=DTYPE,\n",
    "                    initializer=tf.random_uniform_initializer(-1.0, 1.0)\n",
    "            )\n",
    "            # shape (batch_size, unroll_steps, max_chars, embed_dim)\n",
    "            self.char_embedding = tf.nn.embedding_lookup(self.embedding_weights,\n",
    "                                                    self.ids_placeholder)\n",
    "\n",
    "        # the convolutions\n",
    "        def make_convolutions(inp):\n",
    "            with tf.variable_scope('CNN') as scope:\n",
    "                convolutions = []\n",
    "                for i, (width, num) in enumerate(filters):\n",
    "                    if cnn_options['activation'] == 'relu':\n",
    "                        # He initialization for ReLU activation\n",
    "                        # with char embeddings init between -1 and 1\n",
    "                        #w_init = tf.random_normal_initializer(\n",
    "                        #    mean=0.0,\n",
    "                        #    stddev=np.sqrt(2.0 / (width * char_embed_dim))\n",
    "                        #)\n",
    "\n",
    "                        # Kim et al 2015, +/- 0.05\n",
    "                        w_init = tf.random_uniform_initializer(\n",
    "                            minval=-0.05, maxval=0.05)\n",
    "                    elif cnn_options['activation'] == 'tanh':\n",
    "                        # glorot init\n",
    "                        w_init = tf.random_normal_initializer(\n",
    "                            mean=0.0,\n",
    "                            stddev=np.sqrt(1.0 / (width * char_embed_dim))\n",
    "                        )\n",
    "                    w = tf.get_variable(\n",
    "                        \"W_cnn_%s\" % i,\n",
    "                        [1, width, char_embed_dim, num],\n",
    "                        initializer=w_init,\n",
    "                        dtype=DTYPE)\n",
    "                    b = tf.get_variable(\n",
    "                        \"b_cnn_%s\" % i, [num], dtype=DTYPE,\n",
    "                        initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "                    conv = tf.nn.conv2d(\n",
    "                            inp, w,\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding=\"VALID\") + b\n",
    "                    # now max pool\n",
    "                    conv = tf.nn.max_pool(\n",
    "                            conv, [1, 1, max_chars-width+1, 1],\n",
    "                            [1, 1, 1, 1], 'VALID')\n",
    "\n",
    "                    # activation\n",
    "                    conv = activation(conv)\n",
    "                    conv = tf.squeeze(conv, squeeze_dims=[2])\n",
    "\n",
    "                    convolutions.append(conv)\n",
    "\n",
    "            return tf.concat(convolutions, 2)\n",
    "\n",
    "        embedding = make_convolutions(self.char_embedding)\n",
    "\n",
    "        # for highway and projection layers\n",
    "        n_highway = cnn_options.get('n_highway')\n",
    "        use_highway = n_highway is not None and n_highway > 0\n",
    "        use_proj = n_filters != projection_dim\n",
    "\n",
    "        if use_highway or use_proj:\n",
    "            #   reshape from (batch_size, n_tokens, dim) to (-1, dim)\n",
    "            batch_size_n_tokens = tf.shape(embedding)[0:2]\n",
    "            embedding = tf.reshape(embedding, [-1, n_filters])\n",
    "\n",
    "        # set up weights for projection\n",
    "        if use_proj:\n",
    "            assert n_filters > projection_dim\n",
    "            with tf.variable_scope('CNN_proj') as scope:\n",
    "                    W_proj_cnn = tf.get_variable(\n",
    "                        \"W_proj\", [n_filters, projection_dim],\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / n_filters)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_proj_cnn = tf.get_variable(\n",
    "                        \"b_proj\", [projection_dim],\n",
    "                        initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=DTYPE)\n",
    "\n",
    "        # apply highways layers\n",
    "        def high(x, ww_carry, bb_carry, ww_tr, bb_tr):\n",
    "            carry_gate = tf.nn.sigmoid(tf.matmul(x, ww_carry) + bb_carry)\n",
    "            transform_gate = tf.nn.relu(tf.matmul(x, ww_tr) + bb_tr)\n",
    "            return carry_gate * transform_gate + (1.0 - carry_gate) * x\n",
    "\n",
    "        if use_highway:\n",
    "            highway_dim = n_filters\n",
    "\n",
    "            for i in range(n_highway):\n",
    "                with tf.variable_scope('CNN_high_%s' % i) as scope:\n",
    "                    W_carry = tf.get_variable(\n",
    "                        'W_carry', [highway_dim, highway_dim],\n",
    "                        # glorit init\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / highway_dim)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_carry = tf.get_variable(\n",
    "                        'b_carry', [highway_dim],\n",
    "                        initializer=tf.constant_initializer(-2.0),\n",
    "                        dtype=DTYPE)\n",
    "                    W_transform = tf.get_variable(\n",
    "                        'W_transform', [highway_dim, highway_dim],\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / highway_dim)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_transform = tf.get_variable(\n",
    "                        'b_transform', [highway_dim],\n",
    "                        initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=DTYPE)\n",
    "\n",
    "                embedding = high(embedding, W_carry, b_carry,\n",
    "                                 W_transform, b_transform)\n",
    "\n",
    "        # finally project down if needed\n",
    "        if use_proj:\n",
    "            embedding = tf.matmul(embedding, W_proj_cnn) + b_proj_cnn\n",
    "\n",
    "        # reshape back to (batch_size, tokens, dim)\n",
    "        if use_highway or use_proj:\n",
    "            shp = tf.concat([batch_size_n_tokens, [projection_dim]], axis=0)\n",
    "            embedding = tf.reshape(embedding, shp)\n",
    "\n",
    "        # at last assign attributes for remainder of the model\n",
    "        self.embedding = embedding\n",
    "\n",
    "\n",
    "    def _build_word_embeddings(self):\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "\n",
    "        # the word embeddings\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.embedding_weights = tf.get_variable(\n",
    "                \"embedding\", [self._n_tokens_vocab, projection_dim],\n",
    "                dtype=DTYPE,\n",
    "            )\n",
    "            self.embedding = tf.nn.embedding_lookup(self.embedding_weights,\n",
    "                                                self.ids_placeholder)\n",
    "\n",
    "\n",
    "    def _build_lstms(self):\n",
    "        # now the LSTMs\n",
    "        # these will collect the initial states for the forward\n",
    "        #   (and reverse LSTMs if we are doing bidirectional)\n",
    "\n",
    "        # parse the options\n",
    "        lstm_dim = self.options['lstm']['dim']\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "        n_lstm_layers = self.options['lstm'].get('n_layers', 1)\n",
    "        cell_clip = self.options['lstm'].get('cell_clip')\n",
    "        proj_clip = self.options['lstm'].get('proj_clip')\n",
    "        use_skip_connections = self.options['lstm']['use_skip_connections']\n",
    "        if use_skip_connections:\n",
    "            print(\"USING SKIP CONNECTIONS\")\n",
    "        else:\n",
    "            print(\"NOT USING SKIP CONNECTIONS\")\n",
    "\n",
    "        # the sequence lengths from input mask\n",
    "        if self.use_character_inputs:\n",
    "            mask = tf.reduce_any(self.ids_placeholder > 0, axis=2)\n",
    "        else:\n",
    "            mask = self.ids_placeholder > 0\n",
    "        sequence_lengths = tf.reduce_sum(tf.cast(mask, tf.int32), axis=1)\n",
    "        batch_size = tf.shape(sequence_lengths)[0]\n",
    "\n",
    "        # for each direction, we'll store tensors for each layer\n",
    "        self.lstm_outputs = {'forward': [], 'backward': []}\n",
    "        self.lstm_state_sizes = {'forward': [], 'backward': []}\n",
    "        self.lstm_init_states = {'forward': [], 'backward': []}\n",
    "        self.lstm_final_states = {'forward': [], 'backward': []}\n",
    "\n",
    "        update_ops = []\n",
    "        for direction in ['forward', 'backward']:\n",
    "            if direction == 'forward':\n",
    "                layer_input = self.embedding\n",
    "            else:\n",
    "                layer_input = tf.reverse_sequence(\n",
    "                    self.embedding,\n",
    "                    sequence_lengths,\n",
    "                    seq_axis=1,\n",
    "                    batch_axis=0\n",
    "                )\n",
    "\n",
    "            for i in range(n_lstm_layers):\n",
    "                if projection_dim < lstm_dim:\n",
    "                    # are projecting down output\n",
    "                    lstm_cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                        lstm_dim, num_proj=projection_dim,\n",
    "                        cell_clip=cell_clip, proj_clip=proj_clip)\n",
    "                else:\n",
    "                    lstm_cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                            lstm_dim,\n",
    "                            cell_clip=cell_clip, proj_clip=proj_clip)\n",
    "\n",
    "                if use_skip_connections:\n",
    "                    # ResidualWrapper adds inputs to outputs\n",
    "                    if i == 0:\n",
    "                        # don't add skip connection from token embedding to\n",
    "                        # 1st layer output\n",
    "                        pass\n",
    "                    else:\n",
    "                        # add a skip connection\n",
    "                        lstm_cell = tf.nn.rnn_cell.ResidualWrapper(lstm_cell)\n",
    "\n",
    "                # collect the input state, run the dynamic rnn, collect\n",
    "                # the output\n",
    "                state_size = lstm_cell.state_size\n",
    "                # the LSTMs are stateful.  To support multiple batch sizes,\n",
    "                # we'll allocate size for states up to max_batch_size,\n",
    "                # then use the first batch_size entries for each batch\n",
    "                init_states = [\n",
    "                    tf.Variable(\n",
    "                        tf.zeros([self._max_batch_size, dim]),\n",
    "                        trainable=False\n",
    "                    )\n",
    "                    for dim in lstm_cell.state_size\n",
    "                ]\n",
    "                batch_init_states = [\n",
    "                    state[:batch_size, :] for state in init_states\n",
    "                ]\n",
    "\n",
    "                if direction == 'forward':\n",
    "                    i_direction = 0\n",
    "                else:\n",
    "                    i_direction = 1\n",
    "                variable_scope_name = 'RNN_{0}/RNN/MultiRNNCell/Cell{1}'.format(\n",
    "                    i_direction, i)\n",
    "                with tf.variable_scope(variable_scope_name):\n",
    "                    layer_output, final_state = tf.nn.dynamic_rnn(\n",
    "                        lstm_cell,\n",
    "                        layer_input,\n",
    "                        sequence_length=sequence_lengths,\n",
    "                        initial_state=tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                            *batch_init_states),\n",
    "                    )\n",
    "\n",
    "                self.lstm_state_sizes[direction].append(lstm_cell.state_size)\n",
    "                self.lstm_init_states[direction].append(init_states)\n",
    "                self.lstm_final_states[direction].append(final_state)\n",
    "                if direction == 'forward':\n",
    "                    self.lstm_outputs[direction].append(layer_output)\n",
    "                else:\n",
    "                    self.lstm_outputs[direction].append(\n",
    "                        tf.reverse_sequence(\n",
    "                            layer_output,\n",
    "                            sequence_lengths,\n",
    "                            seq_axis=1,\n",
    "                            batch_axis=0\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                with tf.control_dependencies([layer_output]):\n",
    "                    # update the initial states\n",
    "                    for i in range(2):\n",
    "                        new_state = tf.concat(\n",
    "                            [final_state[i][:batch_size, :],\n",
    "                             init_states[i][batch_size:, :]], axis=0)\n",
    "                        state_update_op = tf.assign(init_states[i], new_state)\n",
    "                        update_ops.append(state_update_op)\n",
    "    \n",
    "                layer_input = layer_output\n",
    "\n",
    "        self.mask = mask\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "        self.update_state_op = tf.group(*update_ops)\n",
    "\n",
    "\n",
    "def dump_token_embeddings(vocab_file, options_file, weight_file, outfile):\n",
    "    '''\n",
    "    Given an input vocabulary file, dump all the token embeddings to the\n",
    "    outfile.  The result can be used as the embedding_weight_file when\n",
    "    constructing a BidirectionalLanguageModel.\n",
    "    '''\n",
    "    with open(options_file, 'r') as fin:\n",
    "        options = json.load(fin)\n",
    "    max_word_length = options['char_cnn']['max_characters_per_token']\n",
    "\n",
    "    vocab = UnicodeCharsVocabulary(vocab_file, max_word_length)\n",
    "    batcher = Batcher(vocab_file, max_word_length)\n",
    "\n",
    "    ids_placeholder = tf.placeholder('int32',\n",
    "                                     shape=(None, None, max_word_length)\n",
    "    )\n",
    "    model = BidirectionalLanguageModel(options_file, weight_file)\n",
    "    embedding_op = model(ids_placeholder)['token_embeddings']\n",
    "\n",
    "    n_tokens = vocab.size\n",
    "    embed_dim = int(embedding_op.shape[2])\n",
    "\n",
    "    embeddings = np.zeros((n_tokens, embed_dim), dtype=DTYPE)\n",
    "\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for k in range(n_tokens):\n",
    "            token = vocab.id_to_word(k)\n",
    "            char_ids = batcher.batch_sentences([[token]])[0, 1, :].reshape(\n",
    "                1, 1, -1)\n",
    "            embeddings[k, :] = sess.run(\n",
    "                embedding_op, feed_dict={ids_placeholder: char_ids}\n",
    "            )\n",
    "\n",
    "    with h5py.File(outfile, 'w') as fout:\n",
    "        ds = fout.create_dataset(\n",
    "            'embedding', embeddings.shape, dtype='float32', data=embeddings\n",
    "        )\n",
    "\n",
    "def dump_bilm_embeddings(vocab_file, dataset_file, options_file,\n",
    "                         weight_file, outfile):\n",
    "    with open(options_file, 'r') as fin:\n",
    "        options = json.load(fin)\n",
    "    max_word_length = options['char_cnn']['max_characters_per_token']\n",
    "\n",
    "    vocab = UnicodeCharsVocabulary(vocab_file, max_word_length)\n",
    "    batcher = Batcher(vocab_file, max_word_length)\n",
    "\n",
    "    ids_placeholder = tf.placeholder('int32',\n",
    "                                     shape=(None, None, max_word_length)\n",
    "    )\n",
    "    model = BidirectionalLanguageModel(options_file, weight_file)\n",
    "    ops = model(ids_placeholder)\n",
    "\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sentence_id = 0\n",
    "        with open(dataset_file, 'r') as fin, h5py.File(outfile, 'w') as fout:\n",
    "            for line in fin:\n",
    "                sentence = line.strip().split()\n",
    "                char_ids = batcher.batch_sentences([sentence])\n",
    "                embeddings = sess.run(\n",
    "                    ops['lm_embeddings'], feed_dict={ids_placeholder: char_ids}\n",
    "                )\n",
    "                ds = fout.create_dataset(\n",
    "                    '{}'.format(sentence_id),\n",
    "                    embeddings.shape[1:], dtype='float32',\n",
    "                    data=embeddings[0, :, :, :]\n",
    "                )\n",
    "\n",
    "                sentence_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-centre",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
