{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "BERT (Train)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZG0ZfE_63UA",
        "outputId": "6d4c2256-dcc6-4768-8abd-491dde86470a"
      },
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FUswBmOIyfB"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
        "import pickle\n",
        "\n",
        "max_len = 384\n",
        "configuration = BertConfig() "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5o59VVuikpL"
      },
      "source": [
        "## Set-up BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQsI8DoI4He"
      },
      "source": [
        "# Load and Save Tokenizer\n",
        "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "save_path = \"bert_base_uncased/\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "slow_tokenizer.save_pretrained(save_path)\n",
        "\n",
        "# Load the fast tokenizer from saved file\n",
        "tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWSEsKGHizLI"
      },
      "source": [
        "## Loading the SQuAD 2.0 dataset directly from the default source website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ9qOwS5I4ht"
      },
      "source": [
        "train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\"\n",
        "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
        "eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\"\n",
        "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdD3PtbZjhR_"
      },
      "source": [
        "## Preprocessing of the Dataset\n",
        "1. Go through the JSON file and store every record as a `SquadExample` obect.\n",
        "2. Go through each `SquadExample` and create the inputs (`x_train`, `x_eval`) and outputs dictionaries (`y_train`, `y_eval`) for the train and evaluation datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM8IsCeCI4j-"
      },
      "source": [
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Clean context, answer and question\n",
        "        context = \" \".join(str(context).split())\n",
        "        question = \" \".join(str(question).split())\n",
        "        answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Mark the character indexes in context that are in answer\n",
        "        is_char_in_ans = [0] * len(context)\n",
        "        for idx in range(start_char_idx, end_char_idx):\n",
        "            is_char_in_ans[idx] = 1\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer.encode(context)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        ans_token_idx = []\n",
        "        for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\n",
        "                ans_token_idx.append(idx)\n",
        "\n",
        "        # If there is no answer found\n",
        "        if len(ans_token_idx) == 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = ans_token_idx[0]\n",
        "        end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer.encode(question)\n",
        "\n",
        "        # Create inputs\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
        "            tokenized_question.ids[1:]\n",
        "        )\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0:  # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:  # skip if the length of inputs exceed the max_len\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_context.offsets\n",
        "\n",
        "# Loading of SQuAD Training Dataset from the JSON File\n",
        "with open(train_path) as f:\n",
        "    raw_train_data = json.load(f)\n",
        "\n",
        "with open(eval_path) as f:\n",
        "    raw_eval_data = json.load(f)\n",
        "\n",
        "# Create Squad Examples from raw data\n",
        "def create_squad_examples(raw_data):\n",
        "    squad_examples = []\n",
        "    for item in raw_data[\"data\"]:\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                if \"answers\" in qa and len(qa[\"answers\"]) > 0:\n",
        "                  answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                  all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                  start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                  squad_eg = SquadExample(\n",
        "                      question, context, start_char_idx, answer_text, all_answers\n",
        "                  )\n",
        "                  squad_eg.preprocess()\n",
        "                  squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "# Create Input Data and Output Data\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogvt_lQmlwob"
      },
      "source": [
        "## Creating the Training Data and Evaluation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8JrwFBmltuS",
        "outputId": "ab213d26-4b69-480b-82c2-e3aed5b7d1d2"
      },
      "source": [
        "train_squad_examples = create_squad_examples(raw_train_data)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86821 training points created.\n",
            "5928 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiCgjsXnmUsx"
      },
      "source": [
        "## Creating the Question-Answering Model using BERT and Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw6Oh5WxK5Vr"
      },
      "source": [
        "def create_model():   \n",
        "    ## BERT encoder\n",
        "    encoder = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adamax(lr=5e-5, beta_1=0.3, beta_2=0.999, epsilon = 1e-07)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss])\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohz4JCFXmgcX"
      },
      "source": [
        "## Creating a Evaluation Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_yJ5sKgNVXh"
      },
      "source": [
        "# Remove punctuations and articles so that a higher EM Score can be achieved\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuations\n",
        "    exclude = set(string.punctuation)\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    # Remove articles\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    text = re.sub(regex, \" \", text)\n",
        "\n",
        "    # Remove extra white space\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "class ExactMatch(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Each `SquadExample` object contains the character level offsets for each token\n",
        "    in its input paragraph. We use them to get back the span of text corresponding\n",
        "    to the tokens between our predicted start and end tokens.\n",
        "    All the ground-truth answers are also present in each `SquadExample` object.\n",
        "    We calculate the percentage of data points where the span of text obtained\n",
        "    from model predictions matches one of the ground-truth answers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\n",
        "            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8A2Hf89nIPI"
      },
      "source": [
        "## Enabling the Model to be run on Google Collabotary TPU Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jc33AgxLd0F",
        "outputId": "ed0f85dd-0caf-4ea4-c763-133be913e227"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model = create_model()\n",
        "else:\n",
        "    model = create_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.89.16.210:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.89.16.210:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5d34843d70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5d34843d70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5d34843d70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f5d500ebc20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f5d500ebc20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f5d500ebc20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       768         tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       768         tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,776\n",
            "Trainable params: 109,483,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "MLgKt11-XbVo",
        "outputId": "ff2a8337-714c-45d1-8de0-2cb218db31b1"
      },
      "source": [
        "keras.utils.plot_model(model, \"my_first_model.png\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAHBCAYAAACfe/YgAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde5xO9f7+8eue83nGYcZgZsQoEipRjqVUdFIMw7e0o3Nql6K0S/K1005IO1I/1W63q83MYKscOyi1i+kcKZJ2mKSRMBhmxsz790dfs5tYzOmeNfd9v56Px/xh3ete61qHD5c16163x8xMAAAAAH4vJ8jtBAAAAEB9RVkGAAAAHFCWAQAAAAeUZQAAAMBBiNsB4K5Vq1bpscceczsGUGN33XWXunXr5pVlDx482CvLBepSt27ddNddd3ll2Y899phWrVrllWUDdSknJ+eIaVxZDnBbt27VvHnz3I4B1Mi8efO0detWry4/Ly/Pa8sHvG316tVeLbOrVq3S6tWrvbZ8wNvy8vIc+xBXliHp6P+TAnyFx+Px+jruvPNOZWZmen09gDfUxW9Hunbtyr8l8FnZ2dkaMmTIUV/jyjIAAADggLIMAAAAOKAsAwAAAA4oywAAAIADyjIAAADggLIMAAAAOKAsAwAAAA4oywAAAIADyjIAAADggLIMAAAAOKAsAwAAAA4oywAAAIADyjIAAADggLIMAAAAOKAso8qWLFmi+Ph4vfbaa25HqRVlZWWaPn26unfvXu1lrF69WieffLKCgoLk8XjUpEkTPfTQQ7WYsubmz5+vVq1ayePxyOPxKDk5WcOGDXM7ll/ylzEyefJktW3bVpGRkYqOjlbbtm31wAMPqKCgoMrLYozg9/xlnEycOFHt2rVTXFycwsPD1bp1a91zzz3at29flZfFOKmfQtwOAN9jZm5HqDUbN27UiBEj9P777+vUU0+t9nK6du2qr7/+Wv369dPy5cu1YcMGJSQk1GLSmsvIyFBGRoZat26tn3/+Wdu3b3c7kt/ylzHy3nvv6YYbbtAf/vAHRUZGaunSpbrqqquUm5ur119/vUrLYozg9/xlnKxYsUK33Xabhg4dqtDQUC1dulTDhg3T2rVrtXTp0ioti3FSP3FlGVV2ySWXaM+ePbrsssvcjqIDBw5U+4rwF198oXvvvVe33HKLTjvttFpO5r6a7BvUjL+MkbCwMN16661KTExUTEyMBg8erCuuuEJvvPGGfvzxx1pOWvcYI+7yl3ESExOjm266SQ0bNlRsbKwyMzM1YMAALVu2TFu3bq3lpHWPcUJZho977rnnlJ+fX633nnrqqZo/f76uuuoqhYeH13Iy99Vk38B/1OQ8WLBggSIiIipMa968uSRV61fM9Q1jBIfV5FxYtGiRgoODK0xr3LixJKmwsLDG2dzGOKEso4r+/e9/Ky0tTR6PRzNnzpQkzZo1S9HR0YqKitIrr7yiiy66SHFxcUpJSdGcOXPK3/vEE08oIiJCSUlJuvnmm9W0aVNFRESoe/fuys3NLZ/v9ttvV1hYmJKTk8un3XrrrYqOjpbH49HPP/8sSRo1apRGjx6tTZs2yePxqHXr1l7Z5mXLlikuLk6TJk2q8nt9fd+89957ateuneLj4xUREaEOHTpo+fLlkqTrr7++/J619PR0ffbZZ5KkESNGKCoqSvHx8Xr11VclSaWlpRo/frzS0tIUGRmpjh07KisrS5L06KOPKioqSrGxscrPz9fo0aPVvHlzbdiwoVqZ3ebvY2Tjxo1KSEhQixYtyqcxRhgjVeXv4+SHH35QZGSkWrZsWT6NceLD48QQ0LKysqyqp8HWrVtNks2YMaN82v3332+S7K233rI9e/ZYfn6+9erVy6Kjo624uLh8vptuusmio6Ptq6++soMHD9q6deusS5cuFhsba1u2bCmf76qrrrImTZpUWO+UKVNMku3YsaN8WkZGhqWnp1d1s49w1lln2amnnnrU1xYtWmSxsbE2ceLE4y6nb9++Jsl27dpVPq2+7Zv09HSLj48/7raYmeXk5NiECRPsl19+sZ07d1rXrl2tUaNGFdYRHBxsP/zwQ4X3XXnllfbqq6+W/3nMmDEWHh5u8+bNs127dtl9991nQUFB9tFHH1XYR3fccYfNmDHDBg4caF9//XWlMpqZSbKsrKxKz19VVV2+v42R4uJiy8vLsxkzZlh4eLi9+OKLFV5njNT/MTJo0CAbNGhQpeevquos39/GyWH79++32NhYu/322ytMZ5zU73FyjD6UzZVl1Kru3bsrLi5OiYmJGjp0qPbv368tW7ZUmCckJEQnn3yywsPD1a5dO82aNUt79+7V888/71LqY7vkkktUUFCgBx54oEbL8cV9M2jQID344INq0KCBGjZsqP79+2vnzp3asWOHJOmWW25RaWlphXwFBQX66KOPdPHFF0uSDh48qFmzZmnAgAHKyMhQQkKCxo0bp9DQ0CO265FHHtFtt92m+fPnq23btnW3oXXIF8+D1NRUpaSkaMKECXr00Uc1ZMiQCq8zRhgjtc0Xz4XDHn74YTVt2vSIp1gwTnx3nFCW4TVhYWGSpJKSkmPO17lzZ0VFRWn9+vV1Eate8NV9ExoaKunXX4VJ0nnnnaeTTjpJf/vb38o/2T537lwNHTq0/B6+DRs2qLCwUO3bty9fTmRkpJKTk+vNdrnFV86DrVu3Kj8/X//85z/1wgsv6PTTT/f6PYy+sm9+jzFS+3zpXFiwYIGys7O1fPlyxcbGen19vrRvfsvXxgllGfVCeHh4+f8wUZGb+2bx4sXq3bu3EhMTFR4ernvuuafC6x6PRzfffLO+++47vfXWW5Kkf/zjH7ruuuvK59m/f78kady4ceX3pXk8Hm3evNkvPvxSV9w8D0JDQ5WYmKgLL7xQc+fO1bp16/Twww+7kuVoGCM4zM1zYe7cuXrkkUf0zjvv6IQTTnAlw7EwTqqPsgzXlZSUaPfu3UpJSXE7Sr1T1/vm3Xff1fTp0yVJW7Zs0YABA5ScnKzc3Fzt2bNHkydPPuI9w4cPV0REhJ599llt2LBBcXFxFT78lZiYKEmaPn26zKzCz6pVq+pku3xdfRojrVu3VnBwsNatW+d2FEmMEfyXm+NkxowZeumll7RixQo1a9asztd/PIyTmuFLSeC6d955R2amrl27lk8LCQk57q+VAkFd75tPPvlE0dHRkqS1a9eqpKREI0eOVKtWrST9+r//32vQoIGGDBmiuXPnKjY2VjfccEOF11NTUxUREaHPP//cK5kDgRtjZOfOnfrjH/+of/7znxWmb9y4UaWlpUpNTfXauquCMYLD3BgnZqZ7771Xu3bt0sKFCxUSUj9rFeOkZriyjDpXVlamXbt26dChQ1qzZo1GjRqltLQ0DR8+vHye1q1b65dfftHChQtVUlKiHTt2aPPmzUcsq2HDhtq2bZu+//577d271ysDf+nSpdV+3E9VubVvSkpK9NNPP+mdd94p/wsuLS1NkvTmm2/q4MGD2rhxY4VHD/3WLbfcoqKiIi1atOiILxiIiIjQiBEjNGfOHM2aNUsFBQUqLS1VXl6eX3yxhTfUhzESHR2t119/XStWrFBBQYFKSkr02Wef6ZprrlF0dLTuuuuu8nkZI4wRN9SHcfLVV1/p0Ucf1TPPPKPQ0NAKtwd4PB5NnTq1fF7GiQ+Pk0o9TwN+q6qPjpsxY4YlJyebJIuKirL+/fvbk08+aVFRUSbJTjzxRNu0aZPNnj3b4uLiTJK1aNHCvvnmGzP79ZE2oaGh1rx5cwsJCbG4uDi74oorbNOmTRXWs3PnTjv33HMtIiLCWrZsaX/84x/t7rvvNknWunXr8sfffPrpp9aiRQuLjIy0nj172vbt2yu9LatWrbIePXpY06ZNTZJJsuTkZOvevbutXLmyfL4lS5ZYbGysPfTQQ47LWr16tZ1yyikWFBRUvpxJkybVq33z1FNPWXp6evm2Ov0sWLCgfF1jx461hg0bWkJCgg0ePNhmzpxpkiw9Pb3CI4jMzE4//XT705/+dNT9U1RUZGPHjrW0tDQLCQmxxMREy8jIsHXr1tnkyZMtMjLSJFlqauoRjyWrDNWjR8f50xjp37+/tWzZ0mJiYiw8PNzS09Nt6NChtnbt2grzMUbq/xipb4+O85dxsnbt2mOeK1OmTCmfl3FSv8fJsR4dR1kOcNV5znJN3HTTTdawYcM6W58v8fV9c/HFF9t3333nyrrrU1muKV8/D7zJ1/eNm2OkvpXlmvL1c8GbfH3fuDVOeM4y6pXDj4rBkXxp3/z2V3Fr1qxRREREhW+rQvX50nlQ13xp3zBGvMuXzoW65kv7xhfGCWUZfmP9+vVH3C92tJ+hQ4e6HdUvjB07Vhs3btQ333yjESNG6M9//rPbkXAcjJG6xRjxTYyTuuUL44SyjDpz33336fnnn9eePXvUsmVLzZs3r1aX37Zt2yMeJ3O0n7lz59bqemuDt/eNN0RFRalt27Y6//zzNWHCBLVr187tSD6PMeKMMYLDGCfOGCfe4TH7v69KQUDKzs7WkCFDxGkAX+bxeJSVlaXMzEyfXD7gbYMHD5Yk5eTk+OTyAW87Rh/K4coyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4CDE7QCoHwYPHux2BKBemz59unJyctyOAVTL6tWr1bVrV6+vg39L4Kvy8vIcX6MsB7jU1FQNGjTI7Rh+7eOPP5Ykde7c2eUk/mvQoEFKTU316vIBX9a1a1d169bNa8v35rKBupCSkuL4d73HzKyO8wABJTMzU5KUnZ3tchIAAFBFOdyzDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADigLAMAAAAOKMsAAACAA8oyAAAA4ICyDAAAADgIcTsA4E/+/ve/6/HHH1dpaWn5tB07dkiSOnToUD4tODhYo0aN0vDhw+s6IgAAqAKPmZnbIQB/sWHDBrVt27ZS83799deVnhcAALgih9swgFrUpk0bdejQQR6Px3Eej8ejDh06UJQBAPABlGWglv3hD39QcHCw4+shISG65ppr6jARAACoLm7DAGrZtm3blJKSIqeh5fF4tGXLFqWkpNRxMgAAUEXchgHUtmbNmql79+4KCjpyeAUFBal79+4UZQAAfARlGfCCq6+++qj3LXs8Hv3hD39wIREAAKgObsMAvOCXX35RkyZNdOjQoQrTg4OD9dNPP6lRo0YuJQMAAFXAbRiANzRs2FAXXHCBQkL++yjz4OBgXXDBBRRlAAB8CGUZ8JJhw4aprKys/M9mpquvvtrFRAAAoKq4DQPwkv3796tx48Y6ePCgJCk8PFw///yzYmJiXE4GAAAqidswAG+Jjo5W//79FRoaqpCQEF1xxRUUZQAAfAxlGfCiq666SocOHVJpaamuvPJKt+MAAIAqCjn+LPCGvLw8ffDBB27HgJeVlpYqIiJCZqZ9+/YpOzvb7UjwMp6jDQD+hXuWXZKdna0hQ4a4HQNALcvKylJmZqbbMQAAtSOHK8su4/8q/u/tt9+Wx+NR79693Y4CLzvaF9EAAHwbZRnwsnPOOcftCAAAoJooy4CXBQXxOVoAAHwV/4oDAAAADijLAAAAgAPKMgAAAOCAsgwAAAA4oCwDAAAADijLAAAAgAPKMgAAAOCAsgwAAAA4oCwDAAAADijLAAAAgAPKMgAAAOCAsgwAAAA4oCz7gaKiIt1xxx1KTk5WVFSUli1bVqn3denSRcHBwTrttNO8nNB3XH/99YqNjZXH49Hnn39eqfdMnTpVSUlJ8ng8evrpp6u0vqFDh8rj8VTqZ9GiRZo/f75atWp1zPlOOOEESXKcNyQkRI0bN9b555+vBQsWVHUXVdrv1//AAw8cc/7HHntMHo9HQUFBatu2rd59990arb+ujyUAwD9Rlv3AtGnTtGzZMq1fv16PP/649u3bV6n3ffTRRzr33HO9nM63PPvss3rmmWeq9J4xY8bogw8+qPY6X3/9de3evVslJSX68ccfJUn9+/dXcXGx9u/fr/z8fN1www2SpIyMDH333XdKT09XfHy8zExmpkOHDqmwsFA//fSToqKijjnvjh07lJWVpR9++EEZGRnKysqqdvZj+e36pV/3bUlJyVHnLS0t1RNPPCFJOu+887R+/XqdffbZNVq/G8cSAOB/KMs+5MCBA+revfsR0xcuXKjOnTsrISFBN954owYNGlSl5Xo8ntqKeASnzPiVx+NRjx49FB8fr5CQkArTQ0NDFRUVpcTERJ1xxhnHXE5wcLAiIyOVlJSkk0466ZjzNmjQQH369NFf//pXSVJ2dnbNN0THPtZnnHGGtm/froULFx719fnz56t58+a1kgMAgNpEWfYhzz33nPLz84+YnpeXp9DQ0GovtybvPR6nzPWZN//z8Htz5swpvxJ8LDfddJMuvfTSSi3TqZD+3uHbNXbv3l2p+Y/nWMd65MiRkqSnnnrqqK8/9thjGj16dK3k+K26PJYAAP9EWfYRo0aN0ujRo7Vp0yZ5PB61bt1ab7zxhlq3bq0ff/xRL7zwgjwej2JiYqq87G+//VZt27ZVdHS0IiMj1atXL/373/+uME9paanGjx+vtLQ0RUZGqmPHjuW/vn/00UcVFRWl2NhY5efna/To0WrevLkuuuiiIzJX1uOPP67o6GgFBQXpjDPOUJMmTRQaGqro6Gh16tRJvXr1UmpqqiIiIpSQkKB77rmnwvvNTI899phOPvlkhYeHq0GDBrriiiu0fv36I+abMmWK2rRpo/DwcMXHx+vuu+8+Is+xtt/JsmXLFBcXp0mTJlV6u+vSmjVrJEnnnHNOheneONbnnXeeTj75ZL399tvasGFDhdfef/99FRYW6sILLzxqzvpwLAEAAczgiqysLKvq7s/IyLD09PQjpjdp0sSuueaaauXo06ePtWrVyv7zn/9YSUmJffnll3bWWWdZRESEffPNN+XzjRkzxsLDw23evHm2a9cuu++++ywoKMg++ugjMzO7//77TZLdcccdNmPGDBs4cKB9/fXXjpkr48EHHzRJlpuba/v377eff/7Z+vXrZ5Js8eLFtmPHDtu/f7/dfvvtJsk+//zz8veOHz/ewsLC7MUXX7Tdu3fbmjVrrFOnTta4cWPbvn17+Xz333+/eTwemzZtmu3atcsKCwvtySefNEn22WefVXr7N27caJLsqaeeKn/PokWLLDY21iZOnFjpbf7xxx9Nkl1++eXHnC89Pd3i4+MrTHvrrbdsypQpx523sLDQli5dai1atLALL7zQ9u3bV2H+2j7W6enp9p///Mf++te/miQbNWpUhdcHDBhgzz//vO3du9ckWZ8+fSq8Xh+OZWVJsqysrCq/DwBQb2VTll1Sn8ryqaeeWmHamjVrTJKNGTPGzMwOHDhgUVFRNnTo0PJ5CgsLLTw83EaOHGlm/y1QBw4cqFTmyjhclvfu3Vs+7YUXXjBJtnbt2vJpH374oUmyuXPnlmeLiYmpkPe38x0ur4WFhRYVFWUXXHBBhfnmzJlToWBVZvtrUrB+qyplWdIRP05l+WjzdujQwV544QUrKioqn9cbx/pwWd69e7dFR0dbgwYNrLCw0MzMNm3aZCkpKVZUVHTUsuxrx5KyDAB+J5vbMHCEDh06KD4+vvzX9Bs2bFBhYaHat29fPk9kZKSSk5OP+FW4t4WFhUmSDh06VD7t8D3Xh5+0sG7dOu3bt0+dO3eu8N4uXbooLCxMubm5kn69/aSwsFB9+vQ55jrr0/b/1m+fcGFmevvttys1b0lJifLy8nTnnXfq9ttvV8eOHfXzzz9L8u62xsfH68orr9SuXbs0d+5cSdL06dM1cuTI8uP6e4FyLAEA9RdlGUcVGhpaXj73798vSRo3blyF5/Vu3rxZhYWFbsY8qsMfWDva/dsJCQnau3evpF8/GClJiYmJx1yer2x/7969NWbMmOPOFxISoubNm2vEiBGaOnWqNmzYoL/85S+SvL+thz/o9/TTT2v37t3KycnRzTff7Dh/oB5LAED9QVnGEQ4dOqRffvlFaWlpkv5bQKZPn17hSqaZadWqVW5GPaqEhARJKi9Sv7V7926lpKRIkiIiIiT9+qUux+Jr218VHTp0kCR99dVXkry/raeddpq6du2qDz/8UDfddJMGDx6sBg0aOM7PsQQAuI2yjCO8/fbbKisrU6dOnSSp/KkTlf0WNLe1b99eMTEx+vjjjytMz83NVXFxcfkzi9u3b6+goCCtXLnymMvzte2vik8++USS1KZNG0l1s62Hry7PmzdPd9555zHn5VgCANxGWfYhDRs21LZt2/T9999r7969jt+GVlXFxcXas2ePDh06pE8//VS33367WrRooeHDh0v69ardiBEjNGfOHM2aNUsFBQUqLS1VXl5e+TfO1XXmY4mIiNDo0aO1YMECvfTSSyooKNDatWt1yy23qGnTprrpppsk/XqVMSMjQ/PmzdNzzz2ngoICrVmzRrNnzz5iedXZ/qVLl9arR8cdOHBAZWVlMjNt27ZNzz//vMaNG6fGjRuXl9a6ONaZmZlq3LixBgwYoFatWh1zmfXlWAIAAlhdfpwQ/1Wdp2F8+umn1qJFC4uMjLSePXtabm6unX766SbJQkJCrFOnTjZv3rwqLfP555+3c88915KSkiwkJMQaNWpk//M//2ObN2+uMF9RUZGNHTvW0tLSLCQkxBITEy0jI8PWrVtnkydPtsjISJNkqamp9uKLLzpm/u2jvo7l8ccft6ioKJNkJ5xwgr333nv2yCOPWHx8vEmyJk2a2Msvv2xz5861Jk2amCRr0KCBzZkzx8zMysrKbMqUKXbiiSdaaGioNWjQwAYMGGAbNmyosJ69e/fa9ddfb40aNbKYmBjr2bOnjR8/3iRZSkqKffHFF8fd/mnTppVniI6OtoEDB5qZ2ZIlSyw2NtYeeuih425vQUGBnX322dawYUOTZEFBQda6dWubNGlShfnef/99O+mkk8qfaJGcnHzEo9YOW7BggeOTMMLDw+3EE0+0kSNH2pYtWyq8r7aO9VNPPVW+/saNG9ttt91WPu8999xjH3zwQfmfx40bZ8nJyeXb3q5dO3vvvffqzbGsLPE0DADwN9keM7O6LOf4VXZ2toYMGSJ2P+A/PB6PsrKylJmZ6XYUAEDtyOE2DAAAAMABZdnPrF+/vsIjsZx+hg4dSjYAAIDjCHE7AGpX27Zt6+2tHfU5GwAAwNFwZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHIS4HSDQZWdnux0B/8fM5PF43I5RZb6aGwAAX0BZdtmQIUPcjgAAAAAHHjMzt0MAbjIzjRgxQgsWLNA777yjTp06uR2pSh5//HHdddddmjlzpkaOHOl2HAAA/EkOV5YR8MaMGaN//vOfWrRokc8VZUkaNWqUSktLddtttyk4OFg33XST25EAAPAblGUEtMmTJ2v69Ol64YUXdOGFF7odp9pGjx6tPXv2aOTIkYqOjtawYcPcjgQAgF+gLCNgvfzyy/rTn/6kadOm6eqrr3Y7To1NnDhRhw4d0vDhwxUcHKz/+Z//cTsSAAA+j7KMgPTmm2/q2muv1b333qs777zT7Ti15uGHH1ZpaamuvvpqBQcHKzMz0+1IAAD4NMoyAs5HH32kAQMGKDMzU5MmTXI7Tq175JFHtG/fPl199dWKjIzUZZdd5nYkAAB8Fk/DQED59ttv1aNHD3Xp0kULFy5USIh//n/RzHTLLbfo+eef17/+9S9dfPHFbkcCAMAX5VCWETC2bdumHj16KCkpSStWrFB0dLTbkbzKzHTjjTfq5Zdf1uLFi3Xuuee6HQkAAF+Tw9ddIyAUFBTokksuUWhoqBYtWuT3RVmSPB6Pnn76aQ0YMECXXnqpVq5c6XYkAAB8DmUZfu/gwYO67LLLtGPHDr3xxhtKTEx0O1KdCQ4O1j/+8Q9ddtll6t+/v3Jzc92OBACAT6Esw6+VlpZq2LBh+uKLL7R48WK1aNHC7Uh1Ljg4WC+++KLOOecc9e3bVx9//LHbkQAA8BmUZfi1O++8U0uWLNFrr72mU0891e04rgkNDdW8efPUs2dPXXDBBfr000/djgQAgE+gLMNvPfjgg5o1a5Zeeukl9erVy+04rgsLC1NOTo46deqkfv36ad26dW5HAgCg3qMswy/9v//3//TnP/9ZTz/9tAYOHOh2nHojMjJSr732mtq1a6fzzjtPX3/9tduRAACo1yjL8Duvvvqqbr31Vk2cOFHXX3+923HqnaioKC1evFht2rTRhRdeqE2bNrkdCQCAeovnLMOvvPvuu+rbt6+GDx+up556yu049dqePXt0wQUXaPv27Vq5cqVatmzpdiQAAOobvpQE/uPLL7/U2WefrbPPPlvz589XcHCw25Hqvd27d6tPnz7as2ePVq5cqebNm7sdCQCA+oSyDP+Ql5en7t27Kz09XUuXLlVERITbkXzGjh07dO6556q4uFgrV65U06ZN3Y4EAEB9QVmG7/v555/Vq1cvhYaG6t1331VCQoLbkXxOfn6+evfurbKyMq1cuVJNmjRxOxIAAPUBX3cN31ZYWKjLL79cRUVFWr58OUW5mpKSkvTGG2/o0KFDuvDCC7Vz5063IwEAUC9QluGzSkpKNGjQIH3zzTdaunQptw/UUPPmzfX2229r7969Ov/887Vr1y63IwEA4DrKMnySmUMHWFsAACAASURBVOnGG2/UypUr9eqrr6pNmzZuR/ILqampevvtt7Vr1y5dfPHF2rt3r9uRAABwFWUZPumee+7Ryy+/rPnz56tbt25ux/ErLVq00BtvvKEtW7aoX79+2rdvn9uRAABwDWUZPufJJ5/UtGnT9Mwzz6hfv35ux/FLJ554olasWKHvvvtOF198sfbv3+92JAAAXEFZhk+ZM2eObr/9dk2dOlXXXHON23H8Wps2bbR8+XJ99dVXGjBggA4ePOh2JAAA6hxlGT5jxYoVGjFihMaMGaO77rrL7TgBoWPHjnrzzTf1ySefaMCAASoqKnI7EgAAdYrnLMMnfPzxxzr33HPVv39/vfTSS/J4PG5HCii5ubm68MIL1adPH2VnZyskJMTtSAAA1AW+lAT136ZNm9SjRw916NBBixcvVlhYmNuRAtIHH3ygvn37ql+/fpozZw6FGQAQCPhSEtRv+fn5uuiii5SWlqZ//etfFGUXde/eXUuXLtXSpUt13XXXqayszO1IAAB4HZeGUG8VFBSoX79+MjMtWrRIMTExbkcKeD179tS//vUv9e/fX8HBwXr22WcVFMT/uQEA/ouyjHqpuLhYgwYN0k8//aT3339fSUlJbkfC/7ngggu0cOFCXX755QoODtbs2bO5hxwA4Lcoy6h3ysrKNGzYMOXm5mrlypU64YQT3I6E3+nbt6/mzp2rzMxMRUdH6/HHH3c7EgAAXkFZRr1z55136pVXXtGSJUt02mmnuR0HDq644grNmTNHQ4cOVXBwsKZNm+Z2JAAAah1lGfXKxIkTNXPmTGVlZalPnz5ux8FxZGRk6G9/+5uGDx+uuLg4Pfjgg25HAgCgVlGWUacKCgr01VdfqWvXrke89swzz+jBBx/UE088oUGDBrmQDtVx9dVXq7S0VNddd51CQ0N13333HXW+LVu2KC0trY7TAQBQM3yMHXXqH//4h84991wtXry4wvTXXntNI0eO1IQJE/THP/7RpXSoruHDh2v27NkaN26cJk+efMTrU6dO1dlnn61Dhw65kA4AgOoLnjBhwgS3QyAwmJmGDRumHTt2aO7cuWrRooVOO+00rV69WpdffrmuueYaTZ061e2YqKZOnTqpQYMGuvvuu9W4cWOdeeaZkqRJkybpT3/6kwoKCtS2bVt16NDB5aQAAFTaV3yDH+rMG2+8oQsvvLDCtJEjR2ru3Lnq2bOn5s+fz7fC+YHp06dr9OjRmjVrlnbv3q0//elPkqSgoCC1adNG69at41FzAABfwdddo+5cdtllWr58uUpKSsqneTwepaam6uuvv1ZUVJSL6VCbJk6cqP/93/+Vmen3f8UsW7ZMffv2dSkZAABVwtddo25s2bJFS5YsqVCUpV9vzfjhhx905ZVX6uDBgy6lQ20yM+3ateuoRTkkJESTJk1yKRkAAFVHWUadeOqppxQcHHzU10pLS7V48WL17dtXBQUFdZwMtcnMdPvtt+uJJ544oihL0qFDh/Tee+9p9erVLqQDAKDquA0DXnfw4EE1bdpUu3fvPu68p59+ul5//XU1bty4DpKhNpWVlemGG27Q3//+d5WVlTnOFxoaqksvvVQLFiyow3QAAFQLt2HA+7Kzs497xTg4OFhJSUm69dZb1aBBgzpKhtq0atUqvfLKK8f98F5JSYleeeUVbdy4sY6SAQBQfZRleN306dMdXwsJCVFERITGjBmjb7/9Vtddd53j7Rqo33r06KHNmzdr2rRpaty48TGfbBIcHKwpU6bUYToAAKqH2zDgVbm5uUf9tr7Q0FCVlZXp2muv1Z///Gc1adLEhXTwlsLCQj3zzDN66KGHtHv37qN+GUloaKg2b96spk2bupAQAIBK4TYMeNfMmTMVGhpa/ueQkBB5PB5ddtllWr9+vWbPnk1R9kNRUVG64447lJeXpyeffFKJiYlH/Y3BE0884UI6AAAqjyvL8Jqff/5ZzZo1U0lJiYKCglRWVqYuXbpo+vTp6tGjh9vxUIeKior0wgsvaNy4cfrll19UWloq6ddSvW3bNsXHx7ucEACAo+LKMrznmWeeKX+ucuvWrbVo0SJ9+OGHFOUAFB4erhtvvFHff/+9pkyZosaNG8vj8aiwsFCzZ892Ox4AAI787soyX6OLulTXw4fzG96WlZWlzMxMt2MAQH2R4/xxdR82atQodevWze0YAW3NmjX68ssvNXDgQEVERLgdp9atWrVKjz/+uCvr9qfzu7i4WG+++aaaNm2q008/3e04AW/IkCFuRwCAescvy3K3bt24MuKyQNj/bpVlfzu/hw0b5nYE/B/KMgAciXuWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZbmemzp1qpKSkuTxePT00097bT1LlixRfHy8XnvttRova/78+WrVqpU8Hk+Fn7CwMCUlJal3796aMmWKdu3aVQvJ4Ybrr79esbGx8ng8+vzzz6v0Xs5pAIAvoSzXc2PGjNEHH3zg9fWYWa0tKyMjQ999953S09MVHx8vM1NZWZny8/OVnZ2tli1bauzYsTrllFP08ccf19p6UXeeffZZPfPMM9V6L+c0AMCXUJaP4cCBA+revXu9W5Y3XHLJJdqzZ48uu+yy8mm1mdnj8SghIUG9e/fW888/r+zsbP3000/l6wVqG+c0AKA2UJaP4bnnnlN+fn69W1ZNmZlycnI0e/bsY87nzcyDBg3S8OHDlZ+f79VfxcN7PB6P2xHKcU4DALwl4MvyypUrdeaZZyoqKkpxcXHq0KGDCgoKNGrUKI0ePVqbNm2Sx+NR69atJUnvvfee2rVrp/j4eEVERKhDhw5avny5JOnRRx9VVFSUYmNjlZ+fr9GjR6t58+a66KKLjrqsmjAzPfbYYzr55JMVHh6uBg0a6IorrtD69esrzFdaWqqHH35Ybdq0UWRkpBo3bqyWLVvq4YcfVmZmpiTp3//+t9LS0uTxeDRz5kxJctz+ZcuWKS4uTpMmTarxNgwfPlyStHTp0gp5x48fr7S0NEVGRqpjx47KysqSJM2aNUvR0dGKiorSK6+8oosuukhxcXFKSUnRnDlzKizb6bgebx3+prb2p5lpypQpatOmjcLDwxUfH6+77767VrNyTnNOA0C9ZH5GkmVlZVVq3n379llcXJxNnjzZDhw4YNu3b7eBAwfajh07zMwsIyPD0tPTK7wnJyfHJkyYYL/88ovt3LnTunbtao0aNSp//f777zdJdscdd9iMGTNs4MCB9vXXXx91WZW1ceNGk2RPPfVU+bTx48dbWFiYvfjii7Z7925bs2aNderUyRo3bmzbt28vn2/SpEkWHBxsr7zyihUWFtonn3xiTZo0sd69e1dYx9atW02SzZgxo3za0TIvWrTIYmNjbeLEicfNnZ6ebvHx8Y6vFxQUmCRLTU0tnzZmzBgLDw+3efPm2a5du+y+++6zoKAg++ijj8zsv/v3rbfesj179lh+fr716tXLoqOjrbi42MyOf1yPt47KyMrKMjeGT1XOb7Pa2Z+H5/N4PDZt2jTbtWuXFRYW2pNPPmmS7LPPPqvydnBO179z2qzq5xcABIDsgC7LX375pUmyRYsWHfX1yhTchx9+2CRZfn6+mf33H74DBw5UeVlOfl8sCgsLLSYmxoYOHVphvg8//NAkVfhHv0uXLnbmmWdWmO/GG2+0oKAgKyoqKp9W2WJRFccrFmZmHo/HEhISzMzswIEDFhUVVWG7CgsLLTw83EaOHGlmR9+/h0vbt99+a2bHPq6VWUdl+EJZrq39WVhYaFFRUXbBBRdUWP6cOXNqrSxzTrt/TptRlgHgKLID+jaMVq1aKSkpScOGDdOECRP0/fffV3kZoaGhkn79NWhdWbdunfbt26fOnTtXmN6lSxeFhYUpNze3fNrBgwePeCpAaWmpQkNDFRwcXCd5nezfv19mpri4OEnShg0bVFhYqPbt25fPExkZqeTk5CN+Ff9bYWFhkqSSkhJJxz6u1V2HL6qt/fntt9+qsLBQffr08VpWzumKOKcBoP4I6LIcGRmpFStWqGfPnpo0aZJatWqloUOH6sCBA47vWbx4sXr37q3ExESFh4frnnvuqcPEv9q9e7ckKSYm5ojXEhIStHfv3vI/X3zxxfrkk0/0yiuv6MCBA/r444+1cOFCXXrppa4Xi2+++UaS1LZtW0m/Fg1JGjduXIVn2W7evFmFhYWVXu6xjmttrcMX1Na25uXlSZISExO9klPinD4ezmkAcE9Al2VJOuWUU/Taa69p27ZtGjt2rLKysjR16tSjzrtlyxYNGDBAycnJys3N1Z49ezR58uQ6TvxreZBUoUActnv3bqWkpJT/ecKECTrvvPM0fPhwxcXFaeDAgcrMzKz2M3Jr07JlyyRJF110kaT/lrHp06fLzCr8rFq1qkrLdjqutbmO+q62tjUiIkKSVFRU5JWcEud0ZXBOA4A7QtwO4KZt27Zp9+7dateunRITE/WXv/xFr7/+ur766qujzr927VqVlJRo5MiRatWqlSR3Hp/Vvn17xcTEHPHlB7m5uSouLtYZZ5xRPm3dunXatGmTduzYoZCQ+nO4t2/frunTpyslJUXXXnutJCk1NVURERFV/ka43zvWca2tdfiC2trW9u3bKygoSCtXrtQtt9xSS+mOXAfntDPOaQBwT0BfWd62bZtuvvlmrV+/XsXFxfrss8+0efNmde3aVZLUsGFDbdu2Td9//7327t2rpk2bSpLefPNNHTx4UBs3bqxwL+Wx/H5Zh+9FrI6IiAiNHj1aCxYs0EsvvaSCggKtXbtWt9xyi5o2baqbbrqpfN7bbrtNaWlp2rdvX5XXc7TMS5curdJjtsxM+/btU1lZmcxMO3bsUFZWlnr06KHg4GAtXLiw/P7OiIgIjRgxQnPmzNGsWbNUUFCg0tJS5eXl6ccff6x07mMd19pahy+orW1NTExURkaG5s2bp+eee04FBQVas2bNcZ9pXNWsnNPOOKcBwEV180HCuqMqfJr7+++/t+7du1uDBg0sODjYmjVrZvfff78dOnTIzMw+/fRTa9GihUVGRlrPnj1t+/btNnbsWGvYsKElJCTY4MGDbebMmSbJ0tPT7bbbbrPIyMjyR0e9+OKL5es62rIqY9q0adakSROTZNHR0TZw4EAzMysrK7MpU6bYiSeeaKGhodagQQMbMGCAbdiwocL7V6xYYY0aNTJJ5T+hoaF28skn2/z5883MbMaMGZacnGySLCoqyvr37++YecmSJRYbG2sPPfSQY+ZXX33VOnbsaFFRURYWFmZBQUEmqfwpAWeeeaZNnDjRdu7cecR7i4qKbOzYsZaWlmYhISGWmJhoGRkZtm7dOnvyySctKirKJNmJJ55omzZtstmzZ1tcXJxJshYtWtg333xz3ON6rHVUli88DcOsdvanmdnevXvt+uuvt0aNGllMTIz17NnTxo8fb5IsJSXFvvjii0pn4pyun+e0GU/DAICjyPaY/e5j5T7O4/EoKyur/MsJAt2sWbO0ceNGTZ8+vXxacXGx7r33Xs2aNUu7du1SZGSkiwl9U3Z2toYMGXLEUxm8jfObc9qbOL8A4Ag59eeGP9S67du36/bbbz/iXsawsDClpaWppKREJSUlFAv4DM5pAEBdC+h7lt2yfv36Co94cvoZOnRojdYTGRmp0NBQPffcc/rpp59UUlKibdu26dlnn9X48eM1dOjQ8nsrgZrgnAYA+CuuLLugbdu2dfLr+/j4eL3++uuaOHGiTjrpJO3fv18xMTE65ZRT9Mgjj+jGG2/0egYEBs5pAIC/oiz7uV69eumNN95wOwZQazinAQB1idswAAAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAceMzO3Q9Qmj8fjdgQEkLoePpzf8LasrCxlZma6HQMA6oucELcT1LasrCy3I/iEN998Uy+99JL+/ve/ux0FVcD5XTW5ubl67LHHNGfOHAUF8Yu0yujevbvbEQCgXvG7K8uonAcffFDz5s3TunXr3I4CeM2iRYt02WWXaf/+/YqKinI7DgDA9+RwqSVA5eXlKSUlxe0YgFeFh4dLkoqKilxOAgDwVZTlAEVZRiCgLAMAaoqyHKAoywgElGUAQE1RlgNUXl6emjdv7nYMwKsoywCAmqIsB6C9e/eqoKCAK8vwe5RlAEBNUZYD0NatWyWJsgy/FxERIYmyDACoPspyAMrLy5NEWYb/48oyAKCmKMsBKC8vT1FRUWrYsKHbUQCvoiwDAGqKshyAeBIGAgVlGQBQU5TlAPTDDz9QlhEQKMsAgJqiLAcgriwjUISGhiooKIiyDACoNspyAKIsI5CEhYVRlgEA1UZZDkB8IQkCSXh4OGUZAFBtlOUAU1hYqF9++YUrywgYlGUAQE1QlgMMz1hGoKEsAwBqgrIcYCjLCDSUZQBATVCWA0xeXp7Cw8OVmJjodhSgTlCWAQA1QVkOMFu3blXz5s3l8XjcjgLUCcoyAKAmKMsBhi8kQaChLAMAaoKyHGB4xjICDWUZAFATlOUAQ1lGoKEsAwBqgrIcYCjLCDSUZQBATVCWA0hRUZF+/vlnyjICCmUZAFATlOUAkpeXJzOjLCOgUJYBADVBWQ4gfCEJAhFlGQBQE5TlAJKXl6fQ0FAlJSW5HQWoM5RlAEBNUJYDSF5enpo1a6bg4GC3owB1hrIMAKgJynIA4QtJEIgoywCAmqAsBxAeG4dARFkGANQEZTmAUJYRiMLDw3Xw4EG3YwAAfBRlOYDk5eWpefPmbscA6hRXlgEANUFZDhAlJSXKz8/nyjICDmUZAFATIW4HQO0rLS3VXXfdpSZNmiglJUWpqanl0ynLCBT79u1TSUmJioqKdODAAX333XfavXu3zEwHDhxQUFCQunfv7nZMAEA95zEzczsEal/Hjh21bt06SVJZWVn59JiYGDVr1kytWrVSamqqTjjhBN17770KCuKXDPB9//nPf5Senq7K/LV25ZVX6uWXX66DVAAAH5ZDQ/JTvXv3VkhISIWiLP16te2bb77RsmXL9Mwzz2jDhg0UZfiNli1bqmvXrvJ4PMedd8CAAXWQCADg62hJfqpHjx4qKSk55jwej0f33HNPHSUC6sYNN9xw3LIcFhamiy66qI4SAQB8GWXZT/Xs2fOYv4oODQ3VFVdcoVNOOaUOUwHel5mZqfDwcMfXg4OD1bdvX0VHR9dhKgCAr6Is+6nmzZuradOmjq+XlJTovvvuq8NEQN2Ijo7W0KFDFRYWdtTXzUyDBg2q41QAAF9FWfZjh+9b/r2QkBCdf/756ty5swupAO+79tprVVxcfNTXPB6PLr300jpOBADwVZRlP9azZ8+jTj906JDGjx9fx2mAutOzZ0+1atXqiOlBQUE655xz1LBhQxdSAQB8EWXZj/Xo0UOHDh2qMC04OFhdunRRr169XEoF1I3rr79eoaGhFaZ5PB4NHjzYpUQAAF/Ec5b9WFlZmeLi4rR///4K05csWcKTAOD3tm3bptTU1AqPT/R4PMrLy1OzZs1cTAYA8CE8Z9mfBQUFqVu3buWP0QoKCtIpp5yifv36uZwM8L5mzZrpggsuKL9v3+PxqEuXLhRlAECVUJb93Nlnn13+q2gz04QJEyr1hQ2AP7j++utVWloq6dcPtmZmZrqcCADga7gNw8+tWLFCffr0kcfjUcuWLbVx40a+sQ8Bo7i4WElJSdqzZ48kadOmTUf94B8AAA64DcPfnXXWWQoODpaZ6YEHHqAoI6CEhYVp+PDhkqR27dpRlAEAVXbkQ3j9wGOPPaZVq1a5HaPeiImJUXFxsV577TUtXrzY7Th17q677lK3bt3cjlHrOM8r5/BVZUk8CaMK/HXcAEBV+eVlxlWrVmn16tVux6g3kpKS1LZt24C8qjxv3jxt3brV7RhewXleOfHx8UpISFBKSorbUXyGP48bAKgqv7yyLEldu3ZVTk6O2zHqhXfffVddunRRZGSk21HqnL9/mJHzvHKWL1+uvn37uh3DZ/j7uAGAqvDbsoz/Ovvss92OALiKogwAqK7A+708AAAAUEmUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeUZQAAAMABZRkAAABwQFkGAAAAHFCWAQAAAAeU5d8oKirSHXfcoeTkZEVFRen8889XUlKSPB6Pnn76abfj1cj8+fPVqlUreTwex58TTjhBkjR16lS/2W4cyZ/P898qKyvT9OnT1b1792ovg3EDAKAs/8a0adO0bNkyrV+/Xo8//rhuvvlmffDBB27HqhUZGRn67rvvlJ6ervj4eJmZzEyHDh1SYWGhfvrpJ0VFRUmSxowZ4zfbjSP583l+2MaNG3X22WfrrrvuUmFhYbWXw7gBAFCWf2PhwoXq3LmzEhISdOONN2rQoEHVWs6BAweOuJp1tGn1QXBwsCIjI5WUlKSTTjqpRsvype0OZP5+nn/xxRe69957dcstt+i0007zyjoYNwAQOCjLv5GXl6fQ0NAaL+e5555Tfn7+cafVNwsXLqzR+311uwONv5/np556qubPn6+rrrpK4eHhXl8f4wYA/BtlWdIbb7yh1q1b68cff9QLL7wgj8ejmJgYx/nfe+89tWvXTvHx8YqIiFCHDh20fPlySdKoUaM0evRobdq0SR6PR61btz7qNEkqLS3V+PHjlZaWpsjISHXs2FFZWVmSpFmzZik6OlpRUVF65ZVXdNFFFykuLk4pKSmaM2dOhTzLli1TXFycJk2a5KU9VD+3G1Xj6+d5bWPcAAAqxfzQoEGDbNCgQVV+X5MmTeyaa66pMG3jxo0myZ566qnyaTk5OTZhwgT75ZdfbOfOnda1a1dr1KhR+esZGRmWnp5eYTlHmzZmzBgLDw+3efPm2a5du+y+++6zoKAg++ijj8zM7P777zdJ9tZbb9mePXssPz/fevXqZdHR0VZcXFy+nEWLFllsbKxNnDjxuNuYnp5u8fHxFaa99dZbNmXKFJ/b7sqQZFlZWVV6j68ItPO8Os466yw79dRTj/oa48aZP48bAKiibK4sV8OgQYP04IMPqkGDBmrYsKH69++vnTt3aseOHZVexsGDBzVr1iwNGDBAGRkZSkhI0Lhx4xQaGqrnn3++wrzdu3dXXFycEhMTNXToUO3fv19btmwpf/2SSy5RQUGBHnjggUqte8+ePRU+zd+nTx+f3G54l78fb8YNAKAyKMu14PD9n6WlpZV+z4YNG1RYWKj27duXT4uMjFRycrLWr1/v+L6wsDBJUklJSTXTqsKn+s1Mb7/9drWW42vbjZoJ9OPNuAGAwERZrobFixerd+/eSkxMVHh4uO65554qL2P//v2SpHHjxlW4WrV58+YaPeqqOnr37q0xY8Ycdz5/224cG8f72Bg3ABAYKMtVtGXLFg0YMEDJycnKzc3Vnj17NHny5CovJzExUZI0ffr0ClerzEyrVq2q7dg1FqjbHag43rWD/QgAvi/E7QC+Zu3atSopKdHIkSPVqlUrSZLH46nyclJTUxUREaHPP/+8tiN6RaBud6DieNcO9iMA+D6uLFdRWlqaJOnNN9/UwYMHtXHjRuXm5laYp2HDhtq2bZu+//577d27VyUlJUdMCw4O1ogRIzRnzhzNmjVLBQUFKi0tVV5enn788ccqZVq6dKnXH4FVH7cb3hMIx5txAwColLp89kZdqeojtb7//ns7/fTTTZKFhIRYp06dbN68eTZt2jRr0qSJSbLo6GgbOHCgmZmNHTvWGjZsaAkJCTZ48GCbOXOmSbL09HTbsmWLffrpp9aiRQuLjIy0nj172vbt2486raioyMaOHWtpaWkWEhJiiYmJlpGRYevWrbMnn3zSoqKiTJKdeOKJtmnTJps9e7bFxcWZJGvRooV98803Zma2ZMkSi42NtYceeshxG99//3076aSTTJJJsuTkZOvTp89R5/WV7a4M+fEjsALtPK+sVatWWY8ePaxp06YVzvfu3bvbypUry+dj3Djz53EDAFWU7TEzq6tiXlcGDx4sScrJyXE5Cdzm8XiUlZWlzMxMt6PUOs5zeIs/jxsAqKIcbsMAAAAAHFCWAdRr69evr/C4NKefoUOHuh0VAOCHeBoGgHqtbdu28sO7xQAAPoIrywAAAIADyjIAAADggLIMAAAAOKAsAwAAAA4oywAAAIADyjIAAADggLIMAAAAOKAsAwAAAA4oywAAAIADyjIAAADggLIMAAAAOKAsAwAAAA4oywAAAIADyjIAAADgIMTtAN6yevVqDR482O0YdcLM5PF43I4BFwTSeQ4AgBv8six369bN7Qh16v3331dcXJw6duzodpR6Z9CgQUpNTXU7hlcE2nleUx9//LHMTF26dHE7Sr3nz+MGAKrKY2bmdghUn5mpUaNGmjhxom677Ta34wD11tVXX609e/bo1VdfdTsKAMB35HDPso/7+uuvtWvXLnXt2tXtKEC9Fh4erqKiIrdjAAB8DGXZx61evVoRERHcggEcB2UZAFAdlGUfl5ubq86dOyssLMztKEC9RlkGAFQHZdnHrV69mlswgEqgLAMAqoOy7MP27t2rdevW6ayzznI7ClDvUZYBANVBWfZhH374oUpLS7myDFQCZRkAUB2UZR+2evVqNWvWTCkpKW5HAeo9yjIAoDooyz4sNzdXPXr0cDsG4BMoywCA6qAs+7APP/yQ+5WBSqIsAwCqg7LsozZt2qSffvqJ+5WBSqIsAwCqg7Lso1avXq3Q0FB16tTJoyj80gAADiZJREFU7SiATwgPD1dxcbHMzO0oAAAfQln2Ubm5uTrttNMUGRnpdhTAJ4SHh8vMVFJS4nYUAIAPoSz7KL6MBKia8PBwSeJWDABAlVCWfdCBAwf0xRdf8OE+oAooywCA6qAs+6BPPvlExcXFXFkGqoCyDACoDsqyD1q9erWSkpKUnp7udhTAZ1CWAQDVQVn2Qbm5uVxVBqqIsgwAqA7Ksg9avXo19ysDVURZBgBUB2XZx2zbtk15eXlcWQaqiLIMAKgOyrKP+eCDDxQUFKTOnTu7HQXwKZRlAEB1UJZ9TG5urtq3b6+4uDi3owA+hbIMAKgOyrKP4ctIgOr5/+3deWwU9RvH8c/S7W45uiwthKtQsEJqxNSCWChIxD+UoBzFUEASI4IQ1IBK1HhADCjEiClBiNFITKA2dFGiUcEQNRG1UDTIpaKgUbwIAvaAqr2e3x+G/bHAlO322J3yfiX9Y2emM0+/k6f7yex3ZwjLAIBYEJZdpK6uTnv37uXLfUAMCMsAgFgQll1k3759qqmp4coyEINOnTrJ6/USlgEAzUJYdpHdu3crGAwqOzs73qUAruT3+wnLAIBmISy7SHl5ufLy8tSpE6cNiAVhGQDQXKQuF+HLfUDLEJYBAM1FWHaJkydP6scff+TLfUALEJYBAM1FWHaJXbt2SZJuvPHGOFcCuBdhGQDQXIRllygvL9fQoUOVnp4e71IA1yIsAwCai7DsEsxXBlqOsAwAaC7Csgs0Njbqiy++YL4y0EKEZQBAcxGWE8wff/yhZcuWadu2bTp16pQk6dChQ6qqquLKMtBChGUAQHN5zMziXQT+r7q6WoFAIPx60KBB6t27t7766it99tlnys3NldfrjWOFgDts3rxZW7dulZnpzz//lCQdPnxYHo9HwWBQ1dXVkqSamhqtXr1a9957bzzLBQAkpi2E5QQUCATCb+SSlJSUJElqaGiQ3+9Xbm6uxo4dq0mTJmncuHHxKhNIaLt379bo0aMvu53H49GxY8eUkZHRDlUBAFxmC9MwEtCAAQMiXjc0NKihoUGS9O+//2r37t1avXq1zpw5E4/yAFcYNWqUhgwZIo/H47iNx+PR8OHDCcoAAEeE5QR09dVXN/kG7/P5VFBQoIkTJ7ZjVYD73HfffeFPZi7F6/WqsLCwHSsCALgNYTkBDR48WMnJyY7rk5KStHbt2nasCHCnu+++W03NNKurq9PUqVPbsSIAgNsQlhNQZmam47qkpCStXLmSj42BKPTu3VsTJkxw/FJsdna2hg4d2s5VAQDchLCcgDIzM1VXV3fRcq/Xq6FDh+rBBx+MQ1WAO82bNy885/98Pp9PM2bMiENFAAA3ISwnoMzMzEt+dNzQ0KANGzZw6zigGe644w6lpaVdtLy2tlYFBQVxqAgA4CaE5QR0qWkYycnJWrBgQVS3wgLwf16vV/fcc89F3wPIyMhQTk5OnKoCALgFYTkB9ezZUykpKeHXHo9HqampWrlyZRyrAtxrzpw5EVObfD6fZs2aFceKAABuQVhOUP369Yt4vXbtWvXo0SNO1QDudu211yo3N1edOv33L48pGACAaBGWE1RWVpak/6Zf5Ofn66677opzRYC7zZ8/P3z/8vT0dOXl5cW5IgCAGxCWE9S5sCxJGzZsaPIhJQAub9asWeEHlBQWFoavMgMA0JSLbqvw66+/qqysLB614DyVlZWSpClTpmj//v3av39/nCvqePLz89vsftX0UWIaOXKkPv/8c6WnpysUCsW7HFxCW/YlAMTCYxfcoywUCnHvUVwRSktL2+xRx/QREJu27EsAiMEWxxv2NvWIWLS9srIyVVRUaOLEifEupUNqr2kt9FFiMTOtWLFCy5Yti3cpuASmmwFIRDzdIkHl5eWF51cCaB0ej0dPPPFEvMsAALgI33BJUARloG1c+HASAACaQlgGAAAAHBCWAQAAAAeEZQAAAMABYRkAAABwQFgGAAAAHBCWAQAAAAeEZQAAAMABYRkAAABwQFgGAAAAHBCWAQAAAAeEZQAAAMABYRkAAABwkLBhedu2berevbvefffdDnm8aJWUlMjj8Sg/P7/V980Yd3ycY6mxsVFFRUWt2kP0JQBcORI2LJtZhz5etEpKSpSVlaVdu3bp6NGjrbpvxrjju9LP8ZEjRzRu3Dg98sgjqqmpabX90pcAcAWxC5SWltolFrepmpoaGz16dIc9XqxOnjxpgwcPtuLiYpNkS5cujXlfjHEkSVZaWtpm+6eP4m/fvn02bdo0Ky4utuuvv95ycnJaZb/0Zdtp674EgBiEEuLK8oYNG3TixIkOe7xYhUIh3X777Zo8ebJSUlK0adOmmK8CMcYdH+c4Uk5Ojt566y3Nnj1bfr+/1fZLXwLAFebC+BzLFbGdO3faNddcY4FAwPx+vw0bNsw++OCDiG02btxoI0aMML/fb126dLHMzExbvny5LV682Hw+n0kySZaVlWWffvqpDRgwwCTZSy+9ZGZm2dnZJsk8Ho8NHz7czp49a2Zmjz76aPi4r7/++mXrifZ4ZmaNjY324osvWnZ2tvl8PgsGgzZlyhT79ttvw9usX7/eunTpYp07d7a3337bJkyYYKmpqda/f38rKSmJGIPt27dbamqqPfvss1GN69ixY+3jjz82M7PJkyebJPvkk08ct2eMo6cEvLJMH7XuOT5fXl6e45Vl+jJxzllb9yUAxCDUKmF5y5Yt9swzz9jp06ft1KlTNmrUKEtPTw+vLyoqMkm2atUqO3XqlJ0+fdpeeeUVmz17tpmZ3XnnnZaVlRWxz19++SXiH3h9fb0NGjTIBg4caPX19RHbPvzww1ZUVBR1PdEcz8xs2bJl5vP5bNOmTVZRUWEHDhyw4cOHW8+ePe348ePh7Z566imTZB999JFVVlbaiRMn7KabbrKuXbtabW1teLv33nvPUlNTbfny5Zcd059//tl69eoV/ls3bdpkkmzu3LmX3J4xbp5EDMv0Ueue4/M1FZbpy8Q5Z4RlAAmodcLyhVauXGmS7MSJE1ZbW2vBYNDGjx8fsU19fb2tWbPGzKL/B37ujScUCoWXnT171gYOHGiVlZVR1RPt8Wpqaqxbt242c+bMiO327NljkiLeWM+9Yfz999/hZevXrzdJdvToUeeBasKqVatszpw54deVlZXm9/stEAhYTU1NxLaMcfPHOBHD8oXoo5b30TlNheXmoC/d3ZcAEIO2mbOcnJwsSWpoaNCBAwdUUVGh2267LWKbpKQkLV68uFn7nTdvnrp37641a9aElxUXF2vq1KkKBAJR1ROtr7/+WmfOnNENN9wQsXzkyJHy+XwqLy9v8vd9Pp8kqa6uLupjnq+kpETTpk0Lvw4EArr11ltVVVWld955J2Jbxji2MU509FHinWP60n3nDABaqlXC8vvvv6+bb75ZvXr1kt/v12OPPRZeV1VVJUkKBoMtPk63bt00f/58lZWVac+ePZKkl19+WYsWLYq6nmhVVFSEj3mhYDCo6urqGP6C6Bw6dEgHDx7UpEmT5PF4wj/n7oO6cePGiO0Z446BPkps9KX7zhkAtIYWh+Vjx46poKBAffr0UXl5uSorK/X888+H1/fr10+SdPLkyZYeSpK0aNEiJScnq6ioSDt37tSAAQOUlZUVdT3ROvcGd6k3hoqKCmVkZMT+R1zGG2+8oVmzZsnMIn5Onz6tzp07a8eOHTp+/Hh4e8bY/eijxEdfuu+cAUBraHFYPnjwoOrq6nT//ffrqquuUkpKijweT3j9oEGDlJaWph07drT0UJKkjIwMFRYW6s0339TSpUv10EMPNaueaA0bNkzdunXTl19+GbG8vLxctbW1GjFiRIv+Didmps2bN+uBBx64aF2PHj00ffp0NTQ0qKSkJLycMXY/+iix0ZfuO2cA0FpaHJYHDhwoSfrwww/1zz//6MiRIxFz2vx+v5588knt3LlTixYt0m+//abGxkZVV1frm2++kSSlpaXp999/108//aTq6urLznVbsmSJ6uvr9ddff+mWW25pVj3RHi8lJUVLlizR1q1bVVxcrKqqKh08eFALFy5U3759tWDBgmaP1fbt2xUIBPTcc885blNWVqZAIKAxY8Zccv3ChQslRX7kyxi7H30UP/RlJDecMwBoVxd+5S+Wb/E//vjjlpaWZsFg0KZPn27r1q0L38fz2LFjZma2bt06u+666ywlJcVSUlIsNzfX1q9fb2Zme/futczMTOvcubONHTvWnn76aevTp49Jsi5dutjkyZMvOub48ePttddei6meaI/X2NhoL7zwgg0ZMsSSk5OtR48eVlBQYN999134WOfuNSrJhgwZYj/88IO9+uqrFggETJJlZmba999/b2Zm27Zta/J+rnPnzrWuXbua1+u1nJwc27t3b8T6FStWWN++fcP3Se3fv394DBnj7y9ZpxMl4N0w6KPWPce7du2yMWPGRPRMnz59LD8/P+K+yPRl4pyztu5LAIhByGMW+eipUCikGTNmxPxEKsANPB6PSktLVVhY2Cb7p4+A5mvrvgSAGGxJiMddAwAAAImIsAzAFQ4fPhxxyzann5kzZ8a7VABAB+KNdwEAEI3s7GymtQAA2h1XlgEAAAAHhGUAAADAAWEZAAAAcEBYBgAAABwQlgEAAAAHhGUAAADAAWEZAAAAcEBYBgAAABwQlgEAAAAHhGUAAADAAWEZAAAAcEBYBgAAABwQlgEAAAAHhGUAAADAgddpRSgUas86gA6JPgIAwN0cw/KMGTPasw6gQ6KPAABwN4+ZWbyLAAAAABLQFuYsAwAAAA4IywAAAIADwjIAAADggLAMAAAAOPgfCbekcTS8PgMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh8shNFNnVYQ"
      },
      "source": [
        "## Training and Evaluation of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-wBQWsUNXA0",
        "outputId": "280abde2-ad50-4229-f92c-6e6d25d28c72"
      },
      "source": [
        "exact_match_callback = ExactMatch(x_eval, y_eval)\n",
        "bert = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=5,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=2,\n",
        "    batch_size=64,\n",
        "    callbacks=[exact_match_callback],\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1334/1334 - 308s - loss: 2.8661 - activation_loss: 1.4914 - activation_1_loss: 1.3748\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch=1, exact match score=0.74\n",
            "Epoch 2/5\n",
            "1334/1334 - 229s - loss: 1.9075 - activation_loss: 1.0108 - activation_1_loss: 0.8966\n",
            "\n",
            "epoch=2, exact match score=0.77\n",
            "Epoch 3/5\n",
            "1334/1334 - 228s - loss: 1.5512 - activation_loss: 0.8266 - activation_1_loss: 0.7246\n",
            "\n",
            "epoch=3, exact match score=0.79\n",
            "Epoch 4/5\n",
            "1334/1334 - 228s - loss: 1.2936 - activation_loss: 0.6935 - activation_1_loss: 0.6001\n",
            "\n",
            "epoch=4, exact match score=0.78\n",
            "Epoch 5/5\n",
            "1334/1334 - 228s - loss: 1.0835 - activation_loss: 0.5842 - activation_1_loss: 0.4994\n",
            "\n",
            "epoch=5, exact match score=0.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UIHdL46nhFn"
      },
      "source": [
        "## Saving of Model Weights to be loaded into BERT (Test) file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Fm-nCUsa_u"
      },
      "source": [
        "import h5py\n",
        "save_path = './my_bert_model'\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "model.save_weights('./my_bert_model/bert.h5', overwrite=True)\n"
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}